Why do people get depressed? At first glance, the answer seems obvious: the mind, like the flesh, is prone to malfunction. Once that malfunction happens — perhaps it’s an errant gene triggering a shortage of some happy chemical — we sink into a emotional stupor and need medical treatment. But this pat explanation obscures a lingering paradox of depression, which is that the mental illness is extremely common. Every year, approximately 7 percent of us will be afflicted by the god-awful mental state that William Styron described as a “gray drizzle of horror . . . a storm of murk.” Obsessed with our pain, we will retreat from everything. We will stop eating, unless we start eating too much. Sex will lose its appeal; sleep will become a frustrating pursuit. We will always be tired, even though we will do less and less. We will think a lot about death.

In recent years, a small cadre of researchers has begun exploring this apparent paradox, trying to understand why states of such extreme sadness are so widespread. (The prevalence of depression exists in stark contrast with every other mental illness – schizophrenia, for example, is seen in less than 1 percent of the population.) I wrote about two of these researchers, Andy Thomson at the University of Virginia and Paul Andrews of Virginia Commonwealth, in the Times Magazine last year. The startling speculation behind their theory revolves around the purpose of rumination, the thought process that defines depression. (The verb is derived from the Latin word for “chewed over,” which describes the act of digestion in cattle, in which they swallow, regurgitate and then rechew their food.) In recent decades, psychiatry has come to see rumination as a dangerous mental habit, because it leads people to fixate on their flaws and problems, thus extending their negative moods. The bleakness of this thought process helps explain why, according to the Yale psychologist Susan Nolen-Hoeksema, people with “ruminative tendencies” are more likely to become depressed. They’re also more likely to become unnerved by stressful events: for instance, Nolen-Hoeksema found that residents of San Francisco who self-identified as ruminators showed significantly more depressive symptoms after the 1989 Loma Prieta earthquake.

Thomson and Andrews wondered if, just maybe, rumination wasn’t all bad. They began with the observation that rumination was often a response to a specific psychological blow:

Imagine, for instance, a depression triggered by a bitter divorce. The ruminations might take the form of regret (“I should have been a better spouse”), recurring counterfactuals (“What if I hadn’t had my affair?”) and anxiety about the future (“How will the kids deal with it? Can I afford my alimony payments?”). While such thoughts reinforce the depression — that’s why therapists try to stop the ruminative cycle — Andrews and Thomson wondered if they might also help people prepare for bachelorhood or allow people to learn from their mistakes. “I started thinking about how, even if you are depressed for a few months, the depression might be worth it if it helps you better understand social relationships,” Andrews says. “Maybe you realize you need to be less rigid or more loving. Those are insights that can come out of depression, and they can be very valuable.”

In other words, Thomson and Andrews imagined depression as a way of forcing the mind to focus on its problems. Although rumination feels terrible, it might make it easier for us to pay continuous attention to our dilemmas. According to Andrews and Thomson, the mood disorder is part of a “coordinated system” that exists “for the specific purpose of effectively analyzing the complex life problem that triggered the depression.” If depression didn’t exist — if we didn’t react to stress and trauma with endless ruminations — then we would be less likely to solve our predicaments.

It’s an intriguing hypothesis (which is why I wanted to write about it), but the evidence for this “analytical rumination” theory is mostly speculative and indirect. (It’s also worth pointing out that the theory has many critics, who make several important points.) However, a brand new paper in the Journal of Abnormal Psychiatry provides an interesting test of the idea. The study itself was simple: A large group of subjects ranging from healthy to clinically depressed played a decision-making task on a computer. Their goal of the task was to hire the best applicant in a simulated job search. Each applicant was assigned a monetary value – some were much better than others – and presented in random order to the subjects.

While this task might seem somewhat arbitrary, the scientists note that it closely resembles a common everyday dilemma. It doesn’t matter if we’re shopping for clothes or going on dates — it’s often unclear when we’ve explored enough options, when we should stop searching and just make a damn decision. Furthermore, this task was designed so that it has a known optimal strategy, with the best decision-makers sifting through a certain number of alternatives.

Here’s where things get interesting: depressed patients approximated the optimal strategy much more closely than non-depressed participants did. The main problem with healthy subjects is that they proved lazy, unwilling to search through enough applicants. Those with depression, on the other hand, were much more willing to keep on considering alternatives, which is why they performed far better on the task. While this study comes with many caveats, it remains an interesting demonstration that depression, at least in specific situations, seems to enhance our analytical skills, making us better at focusing on social dilemmas.

It’s also worth pointing out that this controversial theory of depression builds on a growing literature on the mental benefits of sadness. Joe Forgas, for instance, has repeatedly demonstrated in experiments that negative moods lead to better decisions in complex situations. The reason, Forgas suggests, is rooted in the intertwined nature of mood and cognition: sadness promotes “information-processing strategies best suited to dealing with more-demanding situations.” This helps explain why test subjects who are melancholy — Forgas induces the mood with a short film about death and cancer — are better at judging the accuracy of rumors and recalling past events; they’re also much less likely to stereotype strangers.

In 2009, Forgas ventured beyond the lab and began conducting studies in a small stationery store in suburban Sydney, Australia. The experiment itself was simple: Forgas placed a variety of trinkets, like toy soldiers, plastic animals and miniature cars, near the checkout counter. As shoppers exited, Forgas tested their memory, asking them to list as many of the items as possible. To control for the effect of mood, Forgas conducted the survey on gray, rainy days — he accentuated the weather by playing Verdi’s “Requiem” — and on sunny days, using a soundtrack of Gilbert and Sullivan. The results were clear: shoppers in the “low mood” condition remembered nearly four times as many of the trinkets. The wet weather made them sad, and their sadness made them more aware and attentive.

Perhaps Aristotle was a little bit right when he declared: “All men who have attained excellence in philosophy, in poetry, in art and in politics, even Socrates and Plato, had a melancholic habitus; indeed some suffered even from melancholic disease.”
